{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_length=30\n",
    "trainDF = pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/traindf.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "testDF = pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/testdf.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "predDF = pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/preddf.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prodmap= pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/prodEmbIndxMP.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "usermap= pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/userEmbIndxMP.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "brandmap= pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/brandEmbIndxMP.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "targmap= pd.read_csv('/Users/snakepointid/Documents/project/JDproj/save/targProdEmbIndxMP.csv',\n",
    "                      header=0,encoding='gbk' )\n",
    "\n",
    "prodNum = len(prodmap.mp)+1\n",
    "\n",
    "userNum = len(usermap.mp)+1\n",
    "brandNum = len(brandmap.mp)+1\n",
    "targNum = len(targmap.mp)+1\n",
    "\n",
    "prodmap=dict(zip(prodmap['mp'] ,prodmap['index']))\n",
    "usermap=dict(zip(usermap['mp'] ,usermap['index']))\n",
    "brandmap=dict(zip(brandmap['mp'] ,brandmap['index']))\n",
    "targmap_rerse =dict(zip(targmap['index'],targmap['mp']))\n",
    "targmap=dict(zip(targmap['mp'],targmap['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saticDefault = ['0']*23\n",
    "def indexSplit(index,max_seq_length,mapdict):\n",
    "    tmp = index.split(\"<-\")[::-1]\n",
    "    ret = [mapdict.get(int(tmp[i]),0) if i<len(tmp)else 0 for i in range(max_seq_length)]\n",
    "    return ret\n",
    "def staticFeatSplit(staticFeat,max_seq_length):\n",
    "    tmp = staticFeat.split(\"<-\")[::-1]\n",
    "    ret = [tmp[i].split(\"#\") if i<len(tmp)else saticDefault for i in range(max_seq_length)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainProdSeq = np.array([indexSplit(prod,max_seq_length,prodmap) for prod in trainDF.skuidx],dtype=np.int32)\n",
    "trainUserSeq = np.array([[usermap.get(user,0)]*max_seq_length for user in trainDF.user_id],dtype=np.int32)\n",
    "trainBrandSeq = np.array([indexSplit(brand,max_seq_length,brandmap) for brand in trainDF.brandidx],dtype=np.int32)\n",
    "trainStaticFeatSeq = np.array([staticFeatSplit(staticFeat,max_seq_length) for staticFeat in trainDF.static_feat],dtype=np.float32)\n",
    "ySeq = np.array([targmap.get(int(label),0) for label in trainDF.label],dtype=np.int32)\n",
    "trainSeqLength = np.array(trainDF.seq_length,dtype=np.int32)\n",
    "\n",
    "testProdSeq = np.array([indexSplit(prod,max_seq_length,prodmap) for prod in testDF.skuidx],dtype=np.int32)\n",
    "testUserSeq = np.array([[usermap.get(user,0)]*max_seq_length for user in testDF.user_id],dtype=np.int32)\n",
    "testBrandSeq = np.array([indexSplit(brand,max_seq_length,brandmap) for brand in testDF.brandidx],dtype=np.int32)\n",
    "testStaticFeatSeq = np.array([staticFeatSplit(staticFeat,max_seq_length) for staticFeat in testDF.static_feat],dtype=np.float32)\n",
    "ySeqtest = np.array([targmap.get(int(label),0) for label in testDF.label],dtype=np.int32)\n",
    "testSeqLength = np.array(testDF.seq_length,dtype=np.int32)\n",
    "\n",
    "predProdSeq = np.array([indexSplit(prod,max_seq_length,prodmap) for prod in predDF.skuidx],dtype=np.int32)\n",
    "predUserSeq = np.array([[usermap.get(user,0)]*max_seq_length for user in predDF.user_id],dtype=np.int32)\n",
    "predBrandSeq = np.array([indexSplit(brand,max_seq_length,brandmap) for brand in predDF.brandidx],dtype=np.int32)\n",
    "predStaticFeatSeq = np.array([staticFeatSplit(staticFeat,max_seq_length) for staticFeat in predDF.static_feat],dtype=np.float32)\n",
    "predSeqLength = np.array(predDF.seq_length,dtype=np.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construct the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Prod_size  = prodNum\n",
    "user_size  = userNum\n",
    "brand_size = brandNum\n",
    "\n",
    "prod_embedding_size  =100\n",
    "user_embedding_size  =100\n",
    "brand_embedding_size =50\n",
    "\n",
    "max_step_num    = max_seq_length\n",
    "static_feat_dim = 23\n",
    "n_neurons       = 100\n",
    "\n",
    "n_output        = targNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod_embeddings  = tf.Variable(tf.random_uniform([Prod_size,prod_embedding_size], -1.0, 1.0))\n",
    "user_embeddings  = tf.Variable(tf.random_uniform([user_size,user_embedding_size], -1.0, 1.0))\n",
    "brand_embeddings = tf.Variable(tf.random_uniform([brand_size,brand_embedding_size], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod_idx  = tf.placeholder(tf.int32, shape=[None, max_step_num])\n",
    "user_idx  = tf.placeholder(tf.int32, shape=[None, max_step_num])\n",
    "brand_idx = tf.placeholder(tf.int32, shape=[None, max_step_num])\n",
    "\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "static_feat = tf.placeholder(tf.float32, shape=[None, max_step_num,static_feat_dim])\n",
    "prod_embed  = tf.nn.embedding_lookup(prod_embeddings , prod_idx)\n",
    "user_embed  = tf.nn.embedding_lookup(user_embeddings , user_idx)\n",
    "brand_embed = tf.nn.embedding_lookup(brand_embeddings, brand_idx)\n",
    "\n",
    "y = tf.placeholder(tf.int32,[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_feat=tf.concat([static_feat,prod_embed,user_embed,brand_embed], 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    " \n",
    "basic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell,input_keep_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, final_feat, dtype=tf.float32,sequence_length=seq_length)\n",
    "logits = fully_connected(states.h, n_output, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9b78feb9cd2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   1708\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[1;32m   1710\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 3)."
     ]
    }
   ],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=alpha)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feed data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs=100\n",
    "batch_size=100\n",
    "batch_num = len(ySeq)//batch_size\n",
    "sessMode  = \"init_train\"\n",
    "load_path = \"old\"\n",
    "save_path = \"old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    if sessMode==\"init_train\":\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch in range(batch_num):\n",
    "                prod_batch       = trainProdSeq[batch*batch_size:(batch+1)*batch_size]\n",
    "                user_batch       = trainUserSeq[batch:batch+batch_size]\n",
    "                brand_batch      = trainBrandSeq[batch:batch+batch_size]\n",
    "                static_batch     = trainStaticFeatSeq[batch:batch+batch_size]\n",
    "                seq_length_batch = trainSeqLength[batch:batch+batch_size]\n",
    "                y_batch          = ySeq[batch:batch+batch_size]\n",
    "                sess.run(training_op, feed_dict={\n",
    "                    prod_idx: prod_batch,user_idx:user_batch,brand_idx:brand_batch,static_feat:static_batch, \n",
    "                    seq_length: seq_length_batch,y:y_batch})\n",
    "            train_acc = accuracy.eval(feed_dict={\n",
    "                    prod_idx: trainProdSeq,user_idx:trainUserSeq,brand_idx:trainBrandSeq,static_feat:trainStaticFeatSeq, \n",
    "                    seq_length: trainSeqLength,y:ySeq})\n",
    "            test_acc  = accuracy.eval(feed_dict={\n",
    "                    prod_idx: testProdSeq,user_idx:testUserSeq,brand_idx:testBrandSeq,static_feat:testStaticFeatSeq, \n",
    "                    seq_length: testSeqLength,y:ySeqtest})\n",
    "            print(train_acc,test_acc)\n",
    "        save_path = saver.save(sess,\"/Users/snakepointid/Documents/project/RProj/my code/r相关函数/save/\"+save_path+\"/test.ckpt\")\n",
    "    elif sessMode==\"continue_train\":\n",
    "        saver.restore(sess,\"/Users/snakepointid/Documents/project/RProj/my code/r相关函数/save/\"+load_path+\"/test.ckpt\")\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch in range(batch_num):\n",
    "                prod_batch       = trainProdSeq[batch*batch_size:(batch+1)*batch_size]\n",
    "                user_batch       = trainUserSeq[batch:batch+batch_size]\n",
    "                brand_batch      = trainBrandSeq[batch:batch+batch_size]\n",
    "                static_batch     = trainStaticFeatSeq[batch:batch+batch_size]\n",
    "                seq_length_batch = trainSeqLength[batch:batch+batch_size]\n",
    "                y_batch          = ySeq[batch:batch+batch_size]\n",
    "                sess.run(training_op, feed_dict={\n",
    "                    prod_idx: prod_batch,user_idx:user_batch,brand_idx:brand_batch,static_feat:static_batch, \n",
    "                    seq_length: seq_length_batch,y:y_batch})\n",
    "            train_acc = accuracy.eval(feed_dict={\n",
    "                    prod_idx: trainProdSeq,user_idx:trainUserSeq,brand_idx:trainBrandSeq,static_feat:trainStaticFeatSeq, \n",
    "                    seq_length: trainSeqLength,y:ySeq})\n",
    "            test_acc  = accuracy.eval(feed_dict={\n",
    "                    prod_idx: testProdSeq,user_idx:testUserSeq,brand_idx:testBrandSeq,static_feat:testStaticFeatSeq, \n",
    "                    seq_length: testSeqLength,y:ySeqtest})\n",
    "            print(train_acc,test_acc)\n",
    "        save_path = saver.save(sess,\"/Users/snakepointid/Documents/project/RProj/my code/r相关函数/save/\"+save_path+\"/test.ckpt\")\n",
    "    elif sessMode==\"predict\":\n",
    "        saver.restore(sess,\"/Users/snakepointid/Documents/project/RProj/my code/r相关函数/save/\"+load_path+\"/test.ckpt\")\n",
    "        logits_eval = logits.eval(feed_dict={\n",
    "                    prod_idx: predProdSeq,user_idx:predUserSeq,brand_idx:predBrandSeq,static_feat:predStaticFeatSeq, \n",
    "                    seq_length: predSeqLength})\n",
    "        print(logits_eval.argmax(1))\n",
    "    else:\n",
    "        print(\"wrong session type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predDF['predprod'] = np.array([targmap_rerse.get(pred,-1) for pred in logits_eval.argmax(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDF = predDF[[\"user_id\",\"predprod\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
